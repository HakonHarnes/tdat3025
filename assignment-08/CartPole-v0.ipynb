{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1 - CartPole-v0\n",
    "Implementer Q-læring og bruk det for å løse cartpole-environmentet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import gym \n",
    "import math \n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "env = gym.make('CartPole-v0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Parmeters: cart position, cart velocity, pole angle, pole tip velocity\n",
    "\n",
    "# Hyperparameters \n",
    "BUCKETS = (1, 1, 6, 12) \n",
    "EPISODES = 1000\n",
    "MIN_LEARNING_RATE = 0.1\n",
    "MIN_EPSILON = 0.1\n",
    "DISCOUNT = 1.0\n",
    "DECAY = 25\n",
    "\n",
    "# Visualization variables \n",
    "SHOW_ENV = 200\n",
    "SHOW_STATS = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "q_table = np.random.uniform(low=0, high=1, size=(BUCKETS + (env.action_space.n, )))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "upper_bounds = [env.observation_space.high[0], 0.5, env.observation_space.high[2], math.radians(50) / 1.]\n",
    "lower_bounds = [env.observation_space.low[0], -0.5, env.observation_space.low[2], -math.radians(50) / 1.]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Discretizes the state \n",
    "def discretize_state(obs):\n",
    "    discretized = list()\n",
    "    \n",
    "    for i in range(len(obs)):\n",
    "        scaling = (obs[i] + abs(lower_bounds[i])) / (upper_bounds[i] - lower_bounds[i])\n",
    "        new_obs = int(round((BUCKETS[i] - 1) * scaling))\n",
    "        new_obs = min(BUCKETS[i] - 1, max(0, new_obs))\n",
    "        discretized.append(new_obs)\n",
    "        \n",
    "    return tuple(discretized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Chooses what action to take (random or look in Q-Table)\n",
    "def choose_action(state):\n",
    "    if (np.random.random() < epsilon):\n",
    "        return env.action_space.sample() # Random action\n",
    "    else:\n",
    "        return np.argmax(q_table[state]) # Looks up in the Q-Table "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Updates the Q-Table \n",
    "def update_q(state, action, reward, new_state):\n",
    "    q_table[state][action] += learning_rate * (reward + DISCOUNT * np.max(q_table[new_state]) - q_table[state][action])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Updates epsilon value (logarithmically decreasing)\n",
    "def get_epsilon(episode):\n",
    "    return max(MIN_EPSILON, min(1., 1. - math.log10((episode + 1) / DECAY)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Updates the learning rate (logarithmically decreasing)\n",
    "def get_learning_rate(episode):\n",
    "    return max(MIN_LEARNING_RATE, min(1., 1. - math.log10((episode + 1) / DECAY)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode  Score   Average\n",
      "0\t 16.0\t 0.16\n",
      "50\t 27.0\t 13.12\n",
      "100\t 89.0\t 31.8\n",
      "150\t 180.0\t 94.97\n",
      "200\t 200.0\t 174.65\n",
      "250\t 200.0\t 198.52\n",
      "300\t 200.0\t 200.0\n",
      "350\t 200.0\t 200.0\n",
      "400\t 200.0\t 200.0\n",
      "450\t 200.0\t 200.0\n",
      "500\t 200.0\t 200.0\n",
      "550\t 200.0\t 199.33\n",
      "600\t 200.0\t 199.33\n",
      "650\t 200.0\t 200.0\n",
      "700\t 200.0\t 200.0\n",
      "750\t 200.0\t 200.0\n",
      "800\t 200.0\t 200.0\n",
      "850\t 200.0\t 200.0\n",
      "900\t 200.0\t 200.0\n",
      "950\t 200.0\t 200.0\n",
      "\n",
      "Completed on episode 228\n"
     ]
    }
   ],
   "source": [
    "print('Episode  Score   Average')\n",
    "\n",
    "scores = []\n",
    "successfulEpisode = -1  \n",
    "\n",
    "for episode in range(EPISODES):\n",
    "    render = episode % SHOW_ENV == 0 \n",
    "    \n",
    "    # Resets the state \n",
    "    current_state = discretize_state(env.reset())\n",
    "    \n",
    "    # Updates learning rate and epsilon \n",
    "    learning_rate = get_learning_rate(episode)\n",
    "    epsilon = get_epsilon(episode)\n",
    "            \n",
    "    score = 0\n",
    "    \n",
    "    # Plays the game \n",
    "    done = False\n",
    "    while not done:\n",
    "        \n",
    "        # Renders the current state \n",
    "        if render:\n",
    "            env.render()\n",
    "        \n",
    "        action = choose_action(current_state)              # Chooses action\n",
    "        obs, reward, done, _ = env.step(action)            # Performs action \n",
    "        new_state = discretize_state(obs)                  # Discretizes state\n",
    "        update_q(current_state, action, reward, new_state) # Updates Q-Table\n",
    "        current_state = new_state                          # Updates the current state\n",
    "        score += reward                                    # Updates the score \n",
    "    \n",
    "    scores.append(score)\n",
    "\n",
    "    # Calculates the average of the last 100 episodes \n",
    "    average = sum(scores[-100:]) / 100 \n",
    "    if(average >= 195.0 and successfulEpisode < 0):\n",
    "        successfulEpisode = episode\n",
    "    \n",
    "    # Prints some statistics for every 50th episode \n",
    "    if episode % SHOW_STATS == 0: print(f'{episode}\\t {score}\\t {average}')\n",
    "\n",
    "# Prints the result \n",
    "if successfulEpisode > 0:\n",
    "    print(f'\\nCompleted on episode {successfulEpisode}')\n",
    "else:\n",
    "    print('\\nUnable to complete game')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
